{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iLykei Lecture Series\n",
    "# Advanced Machine Learning and Artificial Intelligence (MScA 32017)\n",
    "\n",
    "# Project: Detection of Toxic Comments\n",
    "\n",
    "The goal of the project is to identify and classify toxic online comments. The project is based on the dataset from [Jigsaw's Toxic Comment ClassificationChallenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), organized by Kaggle. See more information about this contest and brief dataset analysis in the notebook [MScA_32017_AMLAI_TC2_DataOverview.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC2_DataOverview.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Download data from [kaggle.com](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data):\n",
    "\n",
    "`train.csv`, `test.csv`, `test_labels.csv`.\n",
    "\n",
    "Train and test data files format is shown in the notebook [MScA_32017_AMLAI_TC2_DataOverview.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC2_DataOverview.ipynb). Note that part of test data was moved to the train after test labels disclosure. Modified files were created there as `tc_train.csv` and `tc_test.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project steps\n",
    "\n",
    "## Step 1.\n",
    "\n",
    "Download FastText embeddings [crawl-300d-2M.vec](https://s3-us-west-1.amazonaws.com/fasttext-vectors/crawl-300d-2M.vec.zip) (see [MScA_32017_AMLAI_TC1_NLP_Basics.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC1_NLP_Basics.ipynb)).\n",
    "\n",
    "\n",
    "## Step 2.\n",
    "\n",
    "Using function `get_embeddings()` from [MScA_32017_AMLAI_TC3_WineReviewsExample.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC3_WineReviewsExample.ipynb) create embeddings index - a dictionary with words as keys and embedding vectors as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding index from file in .txt format. First line contains \n",
    "# dictionary size and embedding dim. Fields are space separated\n",
    "def get_embeddings(file_name):\n",
    "    embeddings_index = {}\n",
    "    with open(file_name, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            values = line.rstrip().split(' ')\n",
    "            if len(values) > 2:\n",
    "                embeddings_index[values[0]] = np.asarray(values[1:], dtype=\"float32\")\n",
    "    return embeddings_index\n",
    "embeddings_path = './Embeddings/'\n",
    "embeddings_index = get_embeddings(embeddings_path+'crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Download data from [kaggle.com](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data):\n",
    "\n",
    "`train.csv`, `test.csv`, `test_labels.csv`.\n",
    "\n",
    "Train and test data files format is shown in the notebook [MScA_32017_AMLAI_TC2_DataOverview.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC2_DataOverview.ipynb). Note that part of test data was moved to the train after test labels disclosure. Modified files were created there as `tc_train.csv` and `tc_test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "trans_table = str.maketrans({key: ' ' for key in string.digits + '\\r\\n' +\n",
    "                             string.punctuation.replace(\"\\'\",'')})\n",
    "def preprocess(text):\n",
    "    return ' '.join(text.lower().translate(trans_table).split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "\n",
    "Using `CountVectorizer` from `sklearn` package create the vocabulary of all words from comments except rare ones. (See notebook [MScA_32017_AMLAI_TC3_WineReviewsExample.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC3_WineReviewsExample.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "\n",
    "Prepare input data for neural network as shown in  [MScA_32017_AMLAI_TC3_WineReviewsExample.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC3_WineReviewsExample.ipynb). \n",
    "\n",
    "Preparation includes the following actions:\n",
    "- Transform each text to sequence of integer numbers replacing each word with its vocabulary index\n",
    "- Make all vectors same length, truncating sequences longer than defined length and padding shorter ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 6\n",
    "\n",
    "Split train data into train and validation sets using the method of multilabel dataset splitting from [MScA_32017_AMLAI_TC1_NLP_Basics.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC1_NLP_Basics.ipynb))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 7\n",
    "\n",
    "Create neural network, tune it on train and validation sets and make submission. Start with the network architechture from  [MScA_32017_AMLAI_TC3_WineReviewsExample.ipynb](https://ilykei.com/api/fileProxy/documents%2FAdvanced%20Machine%20Learning%2FToxicComments%2FMScA_32017_AMLAI_TC3_WineReviewsExample.ipynb) and try to improve it. \n",
    "\n",
    "**Suggestion**: learn and try using `GlobalAveragePooling1D` or `GlobalMaxPooling1D` layers instead of simple `Flatten` layer. \n",
    "You may also try to use both of them and concatenate their ouputs.\n",
    "\n",
    "MaxPooling layer has already been used in Satelite Image Detection project. The only difference between MaxPooling and AveragePooling is that average used instead of maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission File\n",
    "\n",
    "For each id in the `tc_test.csv` file predict probability for each of the six possible types of comment toxicity (\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"). \n",
    "Columns must be in the same order as shown below. The file should contain header and have the following format:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "id,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
    "00001cee341fdb12,0.8,0.5,0.7,0.5,0.5,0.5\n",
    "0000247867823ef7,0.005,0.5,0.11,0.5,0.5,0.5\n",
    "etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Submissions are evaluated on the mean column-wise ROC AUC. In other words, the score is the average of the individual AUCs of each predicted column.  \n",
    "ROC AUC of your submission should be greater than 0.98 to get 100 points.\n",
    "\n",
    "Upload the saved file using \n",
    "[shiny test application](https://shiny.ilykei.com/courses/AdvancedML/Toxic_Comments).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
